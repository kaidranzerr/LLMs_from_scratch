# Self-Attention
# encoder compress entire input sequence into a single hidden state vector
# in self attention the self refers to the mechanism ability to compute attention weights by relating different positions in a single
# input sequence
# it learns the relationships between various parts of input itself , such as words in sentence